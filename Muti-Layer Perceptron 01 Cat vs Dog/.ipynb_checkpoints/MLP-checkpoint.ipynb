{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import f1_score ,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "        [0, 180, 0, 256, 0, 256])\n",
    "\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    " \n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    " \n",
    "\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawImages = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = 'train/'\n",
    "imagePaths = [mypath+f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/25000\n",
      "[INFO] processed 2000/25000\n",
      "[INFO] processed 3000/25000\n",
      "[INFO] processed 4000/25000\n",
      "[INFO] processed 5000/25000\n",
      "[INFO] processed 6000/25000\n",
      "[INFO] processed 7000/25000\n",
      "[INFO] processed 8000/25000\n",
      "[INFO] processed 9000/25000\n",
      "[INFO] processed 10000/25000\n",
      "[INFO] processed 11000/25000\n",
      "[INFO] processed 12000/25000\n",
      "[INFO] processed 13000/25000\n",
      "[INFO] processed 14000/25000\n",
      "[INFO] processed 15000/25000\n",
      "[INFO] processed 16000/25000\n",
      "[INFO] processed 17000/25000\n",
      "[INFO] processed 18000/25000\n",
      "[INFO] processed 19000/25000\n",
      "[INFO] processed 20000/25000\n",
      "[INFO] processed 21000/25000\n",
      "[INFO] processed 22000/25000\n",
      "[INFO] processed 23000/25000\n",
      "[INFO] processed 24000/25000\n"
     ]
    }
   ],
   "source": [
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    image = cv2.imread(imagePath)\n",
    "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "\n",
    "    #pixels = image_to_feature_vector(image)\n",
    "    pixels = extract_color_histogram(image)\n",
    "    \n",
    "    rawImages.append(pixels)\n",
    "    labels.append(label)\n",
    "    \n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test \n",
    "    = train_test_split(np.array(rawImages), np.array(labels), random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val \n",
    "    = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#X_train /= 255\n",
    "#X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model():\n",
    "     # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(124, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(124, activation='relu'))\n",
    "    model.add(Dropout(0.2))   \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    opt = keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "    #opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "     # compile model\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.6702 - acc: 0.5843 - val_loss: 0.6367 - val_acc: 0.6232\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.6319 - acc: 0.6332 - val_loss: 0.6226 - val_acc: 0.6436\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.6227 - acc: 0.6433 - val_loss: 0.6183 - val_acc: 0.6496\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.6181 - acc: 0.6473 - val_loss: 0.6159 - val_acc: 0.6482\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.6129 - acc: 0.6524 - val_loss: 0.6154 - val_acc: 0.6478\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.6064 - acc: 0.6570 - val_loss: 0.6127 - val_acc: 0.6516\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.6015 - acc: 0.6675 - val_loss: 0.6103 - val_acc: 0.6548\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.5963 - acc: 0.6716 - val_loss: 0.6088 - val_acc: 0.6590\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.5912 - acc: 0.6797 - val_loss: 0.6087 - val_acc: 0.6570\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.5846 - acc: 0.6857 - val_loss: 0.6079 - val_acc: 0.6614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ea34d2cc0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model = classification_model()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model.predict(X_test)\n",
    "y_pred =np.argmax(value,axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66      2462\n",
      "           1       0.67      0.66      0.66      2538\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5000\n",
      "   macro avg       0.66      0.66      0.66      5000\n",
      "weighted avg       0.66      0.66      0.66      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
